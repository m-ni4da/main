{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-ni4da/main/blob/main/pyspark_%E5%95%8F%E9%A1%8C%E9%9B%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark: Apache SparkのPython APIであるPySparkをインストールします。\n",
        "# findspark: PySparkをPythonのシステムパスに追加するためのユーティリティです。\n",
        "# pyarrow: Apache ArrowのPythonバインディングです。PySparkと組み合わせて使用すると、データの高速な相互変換や並列処理が可能になります。\n",
        "# xlrd: Excelファイルを読み取るためのPythonライブラリです。\n",
        "# openpyxl: Excelファイルを読み書きするためのPythonライブラリです。\n",
        "# chardet: 文字エンコーディングを検出するためのPythonライブラリです。\n",
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pyarrow\n",
        "!pip install xlrd\n",
        "!pip install openpyxl\n",
        "!pip install chardet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-2DSNGV49iC",
        "outputId": "730e19e0-7961-442b-913f-38b908b7e073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# PySparkのSparkセッションを使用するために、SparkSession をインポートしています。\n",
        "\n",
        "# from pyspark.sql.types import StringType, StructType, StructField\n",
        "# PySparkで使用するデータ型やスキーマを定義するための StringType, StructType, StructField をインポートしています。\n",
        "\n",
        "# import pyspark.sql.functions as fn\n",
        "# PySparkで使用する関数をまとめてインポートしています。ここでは fn というエイリアスを使っています。\n",
        "\n",
        "# from pyspark.sql.functions import col, lit\n",
        "# データフレームの列へのアクセスや新しい列の追加など、列に関する操作に必要な col と lit をインポートしています。\n",
        "\n",
        "# import pandas as pd\n",
        "# Pandasライブラリを pd というエイリアスでインポートしています。Pandasはデータフレームやシリーズを操作するための強力なライブラリです。\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType, StructType, StructField\n",
        "import pyspark.sql.functions as fn\n",
        "from pyspark.sql.functions import col, lit\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dGgbrIJk5HI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SparkSession.builder: Sparkセッションを構築するためのビルダーオブジェクトを取得します。このビルダーオブジェクトを使用して、セッションの構成を指定します。\n",
        "\n",
        "# appName('pyspark'): Sparkアプリケーションの名前を指定します。この場合、アプリケーションの名前は 'pyspark' です。この名前は、SparkのウェブUIやログなどで識別に使用されます。\n",
        "\n",
        "# getOrCreate(): 既存のSparkセッションを取得するか、新しいセッションを作成します。このメソッドは、既にSparkセッションが存在する場合にはそのセッションを返し、存在しない場合には新しいセッションを作成します。\n",
        "spark = SparkSession.builder.appName('pyspark').getOrCreate()"
      ],
      "metadata": {
        "id": "sdQucDKZEXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このコードは、`chardet` ライブラリを使用して、ファイルの文字エンコーディングを検出する関数を定義し、その関数を使用してファイルの文字エンコーディングを検出します。\n",
        "\n",
        "# 1. `import chardet`: `chardet` ライブラリをインポートします。このライブラリは、与えられたテキストデータの文字エンコーディングを検出するための機能を提供します。\n",
        "\n",
        "# 2. `def detect_encoding(file_path):`: `detect_encoding` という名前の関数を定義します。この関数は、ファイルのパスを受け取り、そのファイルの文字エンコーディングを検出します。\n",
        "\n",
        "# 3. `with open(file_path, 'rb') as file:`: ファイルをバイナリモードで開きます。`'rb'` は読み取り専用でバイナリモードを指定します。\n",
        "\n",
        "# 4. `result = chardet.detect(file.read(10000))`: ファイルから最初の10,000バイトを読み取り、`chardet.detect` 関数を使用して文字エンコーディングを検出します。検出された結果は `result` に格納されます。\n",
        "\n",
        "# 5. `return result['encoding']`: 検出された文字エンコーディングを返します。\n",
        "\n",
        "# 6. `file_name = 'order_history.csv'`: 検出するファイルの名前（またはパス）を指定します。\n",
        "\n",
        "# 7. `encoding = detect_encoding(file_name)`: 検出された文字エンコーディングを取得します。\n",
        "\n",
        "# 8. `print(f\"Detected encoding: {encoding}\")`: 検出された文字エンコーディングを表示します。\n",
        "import chardet\n",
        "\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "\n",
        "        result = chardet.detect(file.read(10000))\n",
        "        return result['encoding']\n",
        "\n",
        "file_name = 'order_history.csv'  # CSVファイル名(別の階層にある場合はパス)\n",
        "encoding = detect_encoding(file_name)\n",
        "print(f\"Detected encoding: {encoding}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0-UjsmD5Jjo",
        "outputId": "f661df82-29e8-4234-8425-23e27cc5ade8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected encoding: ascii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# このコードは、PySparkを使用してCSVファイルからデータフレームを読み込むためのコードです。各CSVファイルは異なる文字エンコーディングを使用している可能性があるため、それぞれのファイルに対して異なるエンコーディングを指定しています。\n",
        "\n",
        "# 1. `member_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"ascii\").load(\"members.csv\")`:\n",
        "#    - \"members.csv\" ファイルを読み込んで、データフレーム `member_sdf` を作成します。\n",
        "#    - `format(\"csv\")` は、読み込むファイルのフォーマットがCSVであることを指定します。\n",
        "#    - `option(\"header\", \"true\")` は、CSVファイルの1行目がヘッダーであることを指定します。\n",
        "#    - `option(\"encoding\", \"ascii\")` は、CSVファイルのエンコーディングをASCIIとして指定します。\n",
        "\n",
        "# 2. `product_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"utf-8\").load(\"products.csv\")`:\n",
        "#    - \"products.csv\" ファイルを読み込んで、データフレーム `product_sdf` を作成します。\n",
        "#    - `option(\"encoding\", \"utf-8\")` は、CSVファイルのエンコーディングをUTF-8として指定します。\n",
        "\n",
        "# 3. `order_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"ascii\").load(\"order_history.csv\")`:\n",
        "#    - \"order_history.csv\" ファイルを読み込んで、データフレーム `order_sdf` を作成します。\n",
        "#    - `option(\"encoding\", \"ascii\")` は、CSVファイルのエンコーディングをASCIIとして指定します。\n",
        "\n",
        "# 各ファイルに異なるエンコーディングが使用されている場合、それぞれのファイルに対して適切なエンコーディングを指定することが重要です。これにより、データの正確な読み取りが確保されます。\n",
        "member_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"ascii\").load(\"members.csv\")\n",
        "product_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"utf-8\").load(\"products.csv\")\n",
        "order_sdf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"ascii\").load(\"order_history.csv\")"
      ],
      "metadata": {
        "id": "h274Y1eJ5NrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "member_sdf.show()"
      ],
      "metadata": {
        "id": "dH-JmtL-5Sk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e91009-c8d8-4726-a3b5-48869ce0e339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+\n",
            "| member_id|age|gender|\n",
            "+----------+---+------+\n",
            "| cograph_1| 58|  Male|\n",
            "| cograph_2| 44|Female|\n",
            "| cograph_3| 50|Female|\n",
            "| cograph_4| 62|Female|\n",
            "| cograph_5| 59|  Male|\n",
            "| cograph_6| 30|  Male|\n",
            "| cograph_7| 50|Female|\n",
            "| cograph_8| 38|  Male|\n",
            "| cograph_9| 39|  Male|\n",
            "|cograph_10| 44|Female|\n",
            "|cograph_11| 41|  Male|\n",
            "|cograph_12| 55|  Male|\n",
            "|cograph_13| 48|  Male|\n",
            "|cograph_14| 41|  Male|\n",
            "|cograph_15| 44|Female|\n",
            "|cograph_16| 43|Female|\n",
            "|cograph_17| 55|Female|\n",
            "|cograph_18| 38|Female|\n",
            "|cograph_19| 43|Female|\n",
            "|cograph_20| 31|  Male|\n",
            "+----------+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "member_sdf.select(\"member_id\").show()"
      ],
      "metadata": {
        "id": "2WhGFPZq5Wxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980f5446-082a-4c6b-fa30-3eede78986d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "| member_id|\n",
            "+----------+\n",
            "| cograph_1|\n",
            "| cograph_2|\n",
            "| cograph_3|\n",
            "| cograph_4|\n",
            "| cograph_5|\n",
            "| cograph_6|\n",
            "| cograph_7|\n",
            "| cograph_8|\n",
            "| cograph_9|\n",
            "|cograph_10|\n",
            "|cograph_11|\n",
            "|cograph_12|\n",
            "|cograph_13|\n",
            "|cograph_14|\n",
            "|cograph_15|\n",
            "|cograph_16|\n",
            "|cograph_17|\n",
            "|cograph_18|\n",
            "|cograph_19|\n",
            "|cograph_20|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "member_sdf.select(\"gender\", \"member_id\").show(5)"
      ],
      "metadata": {
        "id": "bMVEKFAt5Z2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69032baa-c615-4d00-9b16-800c38596ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+\n",
            "|gender|member_id|\n",
            "+------+---------+\n",
            "|  Male|cograph_1|\n",
            "|Female|cograph_2|\n",
            "|Female|cograph_3|\n",
            "|Female|cograph_4|\n",
            "|  Male|cograph_5|\n",
            "+------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_sdf.filter(col(\"price\").cast(\"int\") >= 1000).show()"
      ],
      "metadata": {
        "id": "q_rMXtPk5cq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3201058b-55a3-4378-85fe-42dfcc39cb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------------+------+\n",
            "|product_id|            product_name| price|\n",
            "+----------+------------------------+------+\n",
            "|         1|      ハンバーグステーキ|2200.0|\n",
            "|         2|          シーザーサラダ|2100.0|\n",
            "|         3|        クラムチャウダー|1400.0|\n",
            "|         4|        マルゲリータピザ|1300.0|\n",
            "|         5|スパゲッティカルボナーラ|1300.0|\n",
            "|         6|          ローストチキン|1300.0|\n",
            "|         7|          ビーフシチュー|1500.0|\n",
            "|         8|              オムライス|2600.0|\n",
            "|         9|      シーフードパエリア|2000.0|\n",
            "|        10|            ラタトゥイユ|1900.0|\n",
            "+----------+------------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "member_sdf.filter(\n",
        "    (col(\"age\").cast(\"int\") >= 20) & (col(\"gender\") == \"Female\")\n",
        ").show()"
      ],
      "metadata": {
        "id": "6IpRVhzx5foe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a31d687-c271-4413-81d3-b5c6a12feca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------+\n",
            "| member_id|age|gender|\n",
            "+----------+---+------+\n",
            "| cograph_2| 44|Female|\n",
            "| cograph_3| 50|Female|\n",
            "| cograph_4| 62|Female|\n",
            "| cograph_7| 50|Female|\n",
            "|cograph_10| 44|Female|\n",
            "|cograph_15| 44|Female|\n",
            "|cograph_16| 43|Female|\n",
            "|cograph_17| 55|Female|\n",
            "|cograph_18| 38|Female|\n",
            "|cograph_19| 43|Female|\n",
            "|cograph_22| 47|Female|\n",
            "|cograph_24| 33|Female|\n",
            "|cograph_25| 63|Female|\n",
            "|cograph_26| 25|Female|\n",
            "|cograph_27| 40|Female|\n",
            "|cograph_29| 55|Female|\n",
            "|cograph_30| 55|Female|\n",
            "|cograph_31| 42|Female|\n",
            "|cograph_33| 31|Female|\n",
            "|cograph_35| 37|Female|\n",
            "+----------+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_sdf.filter(col(\"price\") <=800).agg(fn.avg(\"price\")).show()"
      ],
      "metadata": {
        "id": "-icOQsEZ5hwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066f1461-0567-4882-eb90-0ea9fc6cb8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|avg(price)|\n",
            "+----------+\n",
            "|     574.2|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "member_sdf.groupBy(\"gender\").agg(fn.count(\"member_id\")).show()"
      ],
      "metadata": {
        "id": "nHOlVqyP5nP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2589172-23a7-4762-e263-e889ace09028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+\n",
            "|gender|count(member_id)|\n",
            "+------+----------------+\n",
            "|Female|              80|\n",
            "|  Male|             120|\n",
            "+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_sdf.groupBy(\"product_id\").agg(\n",
        "    fn.sum(col(\"quantity\").cast(\"int\")).alias(\"cnt\"),\n",
        "    ).select(\"product_id\", \"cnt\").orderBy(col(\"product_id\").cast(\"int\")).show()"
      ],
      "metadata": {
        "id": "wRE22UCxG1eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea5ccde-e031-40cf-ae74-73361bda5019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+\n",
            "|product_id| cnt|\n",
            "+----------+----+\n",
            "|         1| 345|\n",
            "|         2| 329|\n",
            "|         3| 334|\n",
            "|         4| 301|\n",
            "|         5| 309|\n",
            "|         6| 154|\n",
            "|         7| 149|\n",
            "|         8| 166|\n",
            "|         9| 182|\n",
            "|        10| 185|\n",
            "|        11| 552|\n",
            "|        12| 534|\n",
            "|        13| 586|\n",
            "|        14|1260|\n",
            "|        15| 505|\n",
            "+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0u4ubygqG2Oo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}